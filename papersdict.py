dict = {'https://doi.org/10.1145/3531146.3533237': 'How Platform-User Power Relations Shape Algorithmic Accountability: A Case Study of Instant Loan Platforms and Financially Stressed Users in India', 'https://doi.org/10.1145/3531146.3533218': '“There Is Not Enough Information”: On the Effects of Explanations on Perceptions of Informational Fairness and Trustworthiness in Automated Decision-Making', 'https://doi.org/10.1145/3531146.3533072': '#FuckTheAlgorithm: algorithmic imaginaries and political resistance', 'https://doi.org/10.1145/3531146.3533071': 'A Data-driven analysis of the interplay between Criminological theory and predictive policing algorithms', 'https://doi.org/10.1145/3531146.3533165': 'A Data-Driven Simulation of the New York State Foster Care System', 'https://doi.org/10.1145/3531146.3534639': 'A Review of Taxonomies of Explainable Artificial Intelligence (XAI) Methods', 'https://doi.org/10.1145/3531146.3533211': 'ABCinML: Anticipatory Bias Correction in Machine Learning Applications', 'https://doi.org/10.1145/3531146.3533150': 'Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning', 'https://doi.org/10.1145/3531146.3533201': 'Accountable Data: The Politics and Pragmatics of Disclosure Datasets', 'https://doi.org/10.1145/3531146.3533136': 'Achieving Fairness via Post-Processing in Web-Scale Recommender Systems✱', 'https://doi.org/10.1145/3531146.3533203': 'Adaptive Sampling Strategies to Construct Equitable Training Datasets', 'https://doi.org/10.1145/3531146.3533228': 'Adversarial Scrutiny of Evidentiary Statistical Software', 'https://doi.org/10.1145/3531146.3533115': 'Affirmative Algorithms: Relational Equality as Algorithmic Fairness', 'https://doi.org/10.1145/3531146.3533780': 'AI Ethics Statements: Analysis and Lessons Learnt from NeurIPS Broader Impact Statements', 'https://doi.org/10.1145/3531146.3533084': 'AI Opacity and Explainability in Tort Litigation', 'https://doi.org/10.1145/3531146.3533204': 'Algorithmic Fairness and Vertical Equity: Income Fairness with IRS Tax Audit Models', 'https://doi.org/10.1145/3531146.3534631': 'Algorithmic Tools in Public Employment Services: Towards a Jobseeker-Centric Perspective', 'https://doi.org/10.1145/3531146.3533212': 'Algorithms Off-limits?: If digital trade law restricts access to source code of software then accountability will suffer', 'https://doi.org/10.1145/3531146.3533172': 'An Algorithmic Framework for Bias Bounties', 'https://doi.org/10.1145/3531146.3533102': 'An Outcome Test of Discrimination for Ranked Lists', 'https://doi.org/10.1145/3531146.3533114': 'Are “Intersectionally Fair” AI Algorithms Really Fair to Women of Color? A Philosophical Analysis', 'https://doi.org/10.1145/3531146.3533216': 'Assessing Annotator Identity Sensitivity via Item Response Theory: A Case Study in a Hate Speech Corpus', 'https://doi.org/10.1145/3531146.3533200': 'At the Tensions of South and North: Critical Roles of Global South Stakeholders in AI Governance', 'https://doi.org/10.1145/3531146.3533139': 'Attribute Privacy: Framework and Mechanisms', 'https://doi.org/10.1145/3531146.3533174': 'Auditing for Gerrymandering by Identifying Disenfranchised Individuals', 'https://doi.org/10.1145/3531146.3533082': 'Automating Care: Online Food Delivery Work During the CoVID-19 Crisis in India', 'https://doi.org/10.1145/3531146.3533176': 'Brain Computer Interfaces and Human Rights: Brave new rights for a brave new world', 'https://doi.org/10.1145/3531146.3533143': 'Behavioral Use Licensing for Responsible AI', 'https://doi.org/10.1145/3531146.3533121': 'Best vs. All: Equity and Accuracy of Standardized Test Score Reporting', 'https://doi.org/10.1145/3531146.3533160': 'Beyond Fairness: Reparative Algorithms to Address Historical Injustices of Housing Discrimination in the US', 'https://doi.org/10.1145/3531146.3533089': 'Bias in Automated Speaker Recognition', 'https://doi.org/10.1145/3531146.3533192': 'Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?', 'https://doi.org/10.1145/3531146.3533086': 'A Framework for Deprecating Datasets: Standardizing Documentation, Identification, and Communication', 'https://doi.org/10.1145/3531146.3533103': 'Causal Inference Struggles with Agency on Online Platforms', 'https://doi.org/10.1145/3531146.3533219': 'Characterizing Properties and Trade-offs of Centralized Delegation Mechanisms in Liquid Democracy', 'https://doi.org/10.1145/3531146.3533241': 'CounterFAccTual: How FAccT Undermines Its Organizing Principles', 'https://doi.org/10.1145/3531146.3533168': 'Counterfactual Shapley Additive Explanations', 'https://doi.org/10.1145/3531146.3533233': 'Evaluation Gaps in Machine Learning Practice', 'https://doi.org/10.1145/3531146.3533207': 'Critical Tools for Machine Learning: Working with Intersectional Critical Concepts in Machine Learning Systems Design', 'https://doi.org/10.1145/3531146.3534647': 'CrowdWorkSheets: Accounting for Individual and Collective Identities Underlying Crowdsourced Dataset Annotation', 'https://doi.org/10.1145/3531146.3534644': 'Data augmentation for fairness-aware machine learning: Preventing algorithmic bias in law enforcement systems', 'https://doi.org/10.1145/3531146.3533231': 'Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI', 'https://doi.org/10.1145/3531146.3534637': 'Data Governance in the Age of Large-Scale Data-Driven Language Technology', 'https://doi.org/10.1145/3531146.3533105': 'De-biasing “bias” measurement', 'https://doi.org/10.1145/3531146.3533198': 'Decision Time: Normative Dimensions of Algorithmic Speed', 'https://doi.org/10.1145/3531146.3533226': 'Demographic-Reliant Algorithmic Fairness: Characterizing the Risks of Demographic Data Collection in the Pursuit of Fairness', 'https://doi.org/10.1145/3531146.3534626': 'Designing Up with Value-Sensitive Design: Building a Field Guide for Ethical ML Development', 'https://doi.org/10.1145/3531146.3533133': 'Disclosure by Design: Designing information disclosures to support meaningful transparency and accountability', 'https://doi.org/10.1145/3531146.3533781': 'Disentangling the Components of Ethical Research in Machine Learning', 'https://doi.org/10.1145/3531146.3533129': 'Don’t let Ricci v. DeStefano Hold You Back: A Bias-Aware Legal Solution to the Hiring Paradox', 'https://doi.org/10.1145/3531146.3533199': 'Don’t Throw it Away! The Utility of Unlabeled Data in Fair Decision Making', 'https://doi.org/10.1145/3531146.3533188': 'DualCF: Efficient Model Extraction Attack from Counterfactual Explanations', 'https://doi.org/10.1145/3531146.3533070': 'Dynamic Privacy Budget Allocation Improves Data Efficiency of Differentially Private Gradient Descent', 'https://doi.org/10.1145/3531146.3534645': 'Enforcing Group Fairness in Algorithmic Decision Making: Utility Maximization Under Sufficiency', 'https://doi.org/10.1145/3531146.3533112': 'Equi-explanation Maps: Concise and Informative Global Summary Explanations', 'https://doi.org/10.1145/3531146.3533092': 'Equitable Public Bus Network Optimization for Social Good: A Case Study of Singapore', 'https://doi.org/10.1145/3531146.3533119': 'Ethical Concerns and Perceptions of Consumer Neurotechnology from Lived Experiences of Mental Workload Tracking', 'https://doi.org/10.1145/3531146.3533185': 'Evidence for Hypodescent in Visual Semantic AI', 'https://doi.org/10.1145/3531146.3533113': 'Exploring How Machine Learning Practitioners (Try To) Use Fairness Toolkits', 'https://doi.org/10.1145/3531146.3533144': 'Exploring the Role of Grammar and Word Choice in Bias Toward African American English (AAE) in Hate Speech Classification', 'https://doi.org/10.1145/3531146.3533076': 'FAccT-Check on AI regulation: Systematic Evaluation of AI Regulation on the Example of the Legislation on the Use of AI in the Public Sector in the German Federal State of Schleswig-Holstein', 'https://doi.org/10.1145/3531146.3533167': 'FADE: FAir Double Ensemble Learning for Observable and Counterfactual Outcomes', 'https://doi.org/10.1145/3531146.3533085': 'Pareto-Improving Data-Sharing✱', 'https://doi.org/10.1145/3531146.3533238': 'Fair ranking: a critical review, challenges, and future directions', 'https://doi.org/10.1145/3531146.3533146': 'Fair Representation Clustering with Several Protected Classes', 'https://doi.org/10.1145/3531146.3533126': 'Fairness for AUC via Feature Augmentation', 'https://doi.org/10.1145/3531146.3533074': 'Fairness Indicators for Systematic Assessments of Visual Feature Extractors', 'https://doi.org/10.1145/3531146.3533225': 'Fairness-aware Model-agnostic Positive and Unlabeled Learning', 'https://doi.org/10.1145/3531146.3534633': 'Fast online ranking with fairness of exposure', 'https://doi.org/10.1145/3531146.3533159': 'Female, white, 27? Bias Evaluation on Data and Algorithms for Affect Recognition in Faces', 'https://doi.org/10.1145/3531146.3533104': 'Flipping the Script on Criminal Justice Risk Assessment: An actuarial model for assessing the risk the federal sentencing system poses to defendants', 'https://doi.org/10.1145/3531146.3533107': 'Four Years of FAccT: A Reflexive, Mixed-Methods Analysis of Research Contributions, Shortcomings, and Future Prospects', 'https://doi.org/10.1145/3531146.3534634': 'From Demo to Design in Teaching Machine Learning', 'https://doi.org/10.1145/3531146.3533184': 'Gender and Racial Bias in Visual Question Answering Datasets', 'https://doi.org/10.1145/3531146.3533156': 'German AI Start-Ups and “AI Ethics”: Using A Social Practice Lens for Assessing and Implementing Socio-Technical Innovation', 'https://doi.org/10.1145/3531146.3533094': 'GetFair: Generalized Fairness Tuning of Classification Models', 'https://doi.org/10.1145/3531146.3533116': 'Goodbye Tracking? Impact of iOS App Tracking Transparency and Privacy Labels', 'https://doi.org/10.1145/3531146.3533239': 'Healthsheet: Development of a Transparency Artifact for Health Datasets', 'https://doi.org/10.1145/3531146.3533147': 'How are ML-Based Online Content Moderation Systems Actually Used? Studying Community Size, Local Activity, and Disparate Treatment', 'https://doi.org/10.1145/3531146.3533097': 'How Different Groups Prioritize Ethical Values for Responsible AI', 'https://doi.org/10.1145/3531146.3533202': 'How Explainability Contributes to Trust in AI', 'https://doi.org/10.1145/3531146.3533127': 'Human Interpretation of Saliency-based Explanation Over Text', 'https://doi.org/10.1145/3531146.3533221': 'Human-Algorithm Collaboration: Achieving Complementarity and Avoiding Unfairness', 'https://doi.org/10.1145/3531146.3533177': 'Imagining new futures beyond predictive systems in child welfare: A qualitative study with impacted stakeholders', 'https://doi.org/10.1145/3531146.3533140': 'Imperfect Inferences: A Practical Assessment', 'https://doi.org/10.1145/3531146.3533108': 'Interactive Model Cards: A Human-Centered Approach to Model Documentation', 'https://doi.org/10.1145/3531146.3533069': 'Interdisciplinarity, Gender Diversity, and Network Structure Predict the Centrality of AI Organizations', 'https://doi.org/10.1145/3531146.3533245': 'Is calibration a fairness requirement?: An argument from the point of view of moral philosophy and decision theory', 'https://doi.org/10.1145/3531146.3533090': 'It’s Just Not That Simple: An Empirical Study of the Accuracy-Explainability Trade-off in Machine Learning for Public Policy', 'https://doi.org/10.1145/3531146.3533205': 'Justice in Misinformation Detection Systems: An Analysis of Algorithms, Stakeholders, and Potential Harms', 'https://doi.org/10.1145/3531146.3534630': 'Keep Your Friends Close and Your Counterfactuals Closer: Improved Learning From Closest Rather Than Plausible Counterfactual Explanations in an Abstract Setting', 'https://doi.org/10.1145/3531146.3533117': 'Language variation and algorithmic bias: understanding algorithmic bias in British English automatic speech recognition', 'https://doi.org/10.1145/3531146.3533181': 'Learning Resource Allocation Policies from Observational Data with an Application to Homeless Services Delivery', 'https://doi.org/10.1145/3531146.3533073': 'Learning to Break Deep Perceptual Hashing: The Use Case NeuralHash', 'https://doi.org/10.1145/3531146.3533148': 'Learning to Limit Data Collection via Scaling Laws: A Computational Interpretation for the Legal Principle of Data Minimization', 'https://doi.org/10.1145/3531146.3533779': 'Limits and Possibilities for “Ethical AI” in Open Source: A Study of Deepfakes', 'https://doi.org/10.1145/3531146.3534640': 'Limits of Individual Consent and Models of Distributed Consent in Online Social Networks', 'https://doi.org/10.1145/3531146.3534646': 'Locality of Technical Objects and the Role of Structural Interventions for Systemic Change', 'https://doi.org/10.1145/3531146.3533137': 'Making the Unaccountable Internet: The Changing Meaning of Accounting in the Early ARPANET', 'https://doi.org/10.1145/3531146.3533183': 'Markedness in Visual Semantic AI', 'https://doi.org/10.1145/3531146.3533236': 'Marrying Fairness and Explainability in Supervised Learning', 'https://doi.org/10.1145/3531146.3534641': 'Measuring Fairness of Rankings under Noisy Sensitive Information', 'https://doi.org/10.1145/3531146.3533234': 'Measuring the Carbon Intensity of AI in Cloud Instances', 'https://doi.org/10.1145/3531146.3533106': 'Mind the Gap: Autonomous Systems, the Responsibility Gap, and Moral Entanglement', 'https://doi.org/10.1145/3531146.3533081': 'Minimax Demographic Group Fairness in Federated Learning', 'https://doi.org/10.1145/3531146.3533235': 'Model Explanations with Differential Privacy', 'https://doi.org/10.1145/3531146.3533149': 'Model Multiplicity: Opportunities, Concerns, and Solutions', 'https://doi.org/10.1145/3531146.3533162': 'Models for Classifying AI Systems: the Switch, the Ladder, and the Matrix', 'https://doi.org/10.1145/3531146.3533230': 'Models for understanding and quantifying feedback in societal systems', 'https://doi.org/10.1145/3531146.3533178': 'Multi Stage Screening: Enforcing Fairness and Maximizing Efficiency in a Pre-Existing Pipeline', 'https://doi.org/10.1145/3531146.3533154': 'Multi-disciplinary fairness considerations in machine learning for clinical trials', 'https://doi.org/10.1145/3531146.3533180': 'Multiaccurate Proxies for Downstream Fairness', 'https://doi.org/10.1145/3531146.3533166': 'Net benefit, calibration, threshold selection, and training objectives for algorithmic fairness in healthcare', 'https://doi.org/10.1145/3531146.3533224': 'NeuroView-RNN: It’s About Time', 'https://doi.org/10.1145/3531146.3533077': 'News from Generative Artificial Intelligence Is Believed Less', 'https://doi.org/10.1145/3531146.3533123': 'Normative Logics of Algorithmic Accountability', 'https://doi.org/10.1145/3531146.3533232': 'On the Existence of Simpler Machine Learning Models', 'https://doi.org/10.1145/3531146.3533152': 'On the Fairness of Machine-Assisted Human Decisions', 'https://doi.org/10.1145/3531146.3533209': 'On the Power of Randomization in Fair Classification and Representation', 'https://doi.org/10.1145/3531146.3533099': 'Measuring Representational Harms in Image Captioning', 'https://doi.org/10.1145/3531146.3534643': 'People are not coins: Morally distinct types of predictions necessitate different fairness constraints', 'https://doi.org/10.1145/3531146.3533153': 'Post-Hoc Explanations Fail to Achieve their Purpose in Adversarial Contexts', 'https://doi.org/10.1145/3531146.3533229': 'Predictability and Surprise in Large Generative Models', 'https://doi.org/10.1145/3531146.3533155': 'Prediction as Extraction of Discretion', 'https://doi.org/10.1145/3531146.3533222': 'Stop the Spread: A Contextual Integrity Perspective on the Appropriateness of COVID-19 Vaccination Certificates', 'https://doi.org/10.1145/3531146.3533151': 'Promoting Ethical Awareness in Communication Analysis: Investigating Potentials and Limits of Visual Analytics for Intelligence Applications', 'https://doi.org/10.1145/3531146.3534632': 'Promoting Fairness in Learned Models by Learning to Active Learn under Parity Constraints', 'https://doi.org/10.1145/3531146.3533079': 'Providing Item-side Individual Fairness for Deep Recommender Systems', 'https://doi.org/10.1145/3531146.3533170': 'Rational Shapley Values', 'https://doi.org/10.1145/3531146.3533122': 'REAL ML: Recognizing, Exploring, and Articulating Limitations of Machine Learning Research', 'https://doi.org/10.1145/3531146.3533163': 'Regulating Facial Processing Technologies: Tensions Between Legal and Technical Considerations in the Application of Illinois BIPA', 'https://doi.org/10.1145/3531146.3533244': 'Reliable and Safe Use of Machine Translation in Medical Settings', 'https://doi.org/10.1145/3531146.3533138': 'Robots Enact Malignant Stereotypes', 'https://doi.org/10.1145/3531146.3533124': 'Selection in the Presence of Implicit Bias: The Advantage of Intersectional Constraints', 'https://doi.org/10.1145/3531146.3533135': 'Sensible AI: Re-imagining Interpretability and Explainability using Sensemaking Theory', 'https://doi.org/10.1145/3531146.3533206': 'Should attention be all we need? The epistemic and ethical implications of unification in machine learning', 'https://doi.org/10.1145/3531146.3533175': 'Smallset Timelines: A Visual Representation of Data Preprocessing Decisions', 'https://doi.org/10.1145/3531146.3533095': 'Social Inclusion in Curated Contexts: Insights from Museum Practices', 'https://doi.org/10.1145/3531146.3533091': 'South Korean Public Value Coproduction Towards‘AI for Humanity’: A Synergy of Sociocultural Norms and Multistakeholder Deliberation in Bridging the Design and Implementation of National AI Ethics Guidelines', 'https://doi.org/10.1145/3531146.3533128': 'Subverting Fair Image Search with Generative Adversarial Perturbations', 'https://doi.org/10.1145/3531146.3533161': 'Subverting machines, fluctuating identities: Re-learning human categorization', 'https://doi.org/10.1145/3531146.3533217': 'Surfacing Racial Stereotypes through Identity Portrayal', 'https://doi.org/10.1145/3531146.3533215': 'System Safety and Artificial Intelligence', 'https://doi.org/10.1145/3531146.3533169': 'Tackling Algorithmic Disability Discrimination in the Hiring Process: An Ethical, Legal and Technical Analysis', 'https://doi.org/10.1145/3531146.3533088': 'Taxonomy of Risks posed by Language Models', 'https://doi.org/10.1145/3531146.3533111': 'Tech Worker Organizing for Power and Accountability', 'https://doi.org/10.1145/3531146.3533227': "Testing Concerns about Technology's Behavioral Impacts with N-of-one Trials", 'https://doi.org/10.1145/3531146.3533194': 'Confronting Power and Corporate Capture at the FAccT Conference', 'https://doi.org/10.1145/3531146.3533196': 'The Alchemy of Trust: The Creative Act of Designing Trustworthy Socio-Technical Systems', 'https://doi.org/10.1145/3531146.3533186': 'The Algorithmic Imprint', 'https://doi.org/10.1145/3531146.3533190': 'The Case for a Legal Compliance API for the Enforcement of the EU’s Digital Services Act on Social Media Platforms', 'https://doi.org/10.1145/3531146.3534628': 'The Conflict Between Explainable and Accountable Decision-Making Algorithms', 'https://doi.org/10.1145/3531146.3533134': 'The Death of the Legal Subject: How Predictive Algorithms Are (Re)constructing Legal Subjectivity', 'https://doi.org/10.1145/3531146.3534629': 'The Effects of Crowd Worker Biases in Fact-Checking Tasks', 'https://doi.org/10.1145/3531146.3533158': 'The Fallacy of AI Functionality', 'https://doi.org/10.1145/3531146.3533157': 'The Forgotten Margins of AI Ethics', 'https://doi.org/10.1145/3531146.3534635': 'The Long Arc of Fairness: Formalisations and Ethical Discourse', 'https://doi.org/10.1145/3531146.3533110': 'The Model Card Authoring Toolkit: Toward Community-centered, Deliberation-driven AI Design', 'https://doi.org/10.1145/3531146.3533179': 'The Road to Explainability is Paved with Bias: Measuring the Fairness of Explanations', 'https://doi.org/10.1145/3531146.3533240': 'The Spotlight: A General Method for Discovering Systematic Errors in Deep Learning Models', 'https://doi.org/10.1145/3531146.3533083': 'The Values Encoded in Machine Learning Research', 'https://doi.org/10.1145/3531146.3534627': 'Theories of “Gender” in NLP Bias Research', 'https://doi.org/10.1145/3531146.3533118': 'Towards a multi-stakeholder value-based assessment framework for algorithmic systems', 'https://doi.org/10.1145/3531146.3533182': 'Designing for Responsible Trust in AI Systems: A Communication Perspective', 'https://doi.org/10.1145/3531146.3533197': 'Towards Fair Unsupervised Learning', 'https://doi.org/10.1145/3531146.3533132': 'Towards Intersectional Feminist and Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection', 'https://doi.org/10.1145/3531146.3533101': 'Towards Intersectionality in Machine Learning: Including More Identities, Handling Underrepresentation, and Performing Evaluation', 'https://doi.org/10.1145/3531146.3533171': 'Trade-offs between Group Fairness Metrics in Societal Resource Allocation', 'https://doi.org/10.1145/3531146.3533087': 'Treatment Effect Risk: Bounds and Inference', 'https://doi.org/10.1145/3531146.3533145': 'Trucks Don’t Mean Trump: Diagnosing Human Error in Image Analysis', 'https://doi.org/10.1145/3531146.3533243': 'Uncertainty and the Social Planner’s Problem: Why Sample Complexity Matters', 'https://doi.org/10.1145/3531146.3534638': 'Understanding and Being Understood: User Strategies for Identifying and Recovering From Mistranslations in Machine Translation-Mediated Chat', 'https://doi.org/10.1145/3531146.3533189': 'Why Am I Not Seeing It? Understanding Users’ Needs for Counterfactual Explanations in Everyday Recommendations', 'https://doi.org/10.1145/3531146.3534642': 'What Does it Mean for a Language Model to Preserve Privacy?', 'https://doi.org/10.1145/3531146.3533242': 'What is Proxy Discrimination?', 'https://doi.org/10.1145/3531146.3533223': 'What is the Bureaucratic Counterfactual? Categorical versus Algorithmic Prioritization in U.S. Social Policy', 'https://doi.org/10.1145/3531146.3533080': 'What People Think AI Should Infer From Faces', 'https://doi.org/10.1145/3531146.3533078': 'When learning becomes impossible', 'https://doi.org/10.1145/3531146.3533213': 'Who Audits the Auditors? Recommendations from a field scan of the algorithmic auditing ecosystem', 'https://doi.org/10.1145/3531146.3533193': 'Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging'}